{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MINI PROJEKT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "from IPython.core.pylabtools import figsize\n",
    "import sklearn.model_selection as skl_ms\n",
    "import sklearn.metrics as skl_met\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Number words female</th>\n",
       "      <th>Total words</th>\n",
       "      <th>Number of words lead</th>\n",
       "      <th>Difference in words lead and co-lead</th>\n",
       "      <th>Number of male actors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of female actors</th>\n",
       "      <th>Number words male</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Mean Age Male</th>\n",
       "      <th>Mean Age Female</th>\n",
       "      <th>Age Lead</th>\n",
       "      <th>Age Co-Lead</th>\n",
       "      <th>Lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "      <td>6394</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>2631</td>\n",
       "      <td>142.0</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1524</td>\n",
       "      <td>8780</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1219</td>\n",
       "      <td>9</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>5236</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.125000</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>4176</td>\n",
       "      <td>942.0</td>\n",
       "      <td>787</td>\n",
       "      <td>7</td>\n",
       "      <td>1968</td>\n",
       "      <td>1</td>\n",
       "      <td>3079</td>\n",
       "      <td>376.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1073</td>\n",
       "      <td>9855</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>2623</td>\n",
       "      <td>12</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>5342</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.222222</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1317</td>\n",
       "      <td>7688</td>\n",
       "      <td>3835.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>8</td>\n",
       "      <td>1988</td>\n",
       "      <td>4</td>\n",
       "      <td>2536</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1034</td>\n",
       "      <td>303</td>\n",
       "      <td>2398</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>1166</td>\n",
       "      <td>5</td>\n",
       "      <td>1973</td>\n",
       "      <td>2</td>\n",
       "      <td>761</td>\n",
       "      <td>174.0</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>632</td>\n",
       "      <td>8404</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>187</td>\n",
       "      <td>6</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>5820</td>\n",
       "      <td>172.0</td>\n",
       "      <td>37.166667</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1036</td>\n",
       "      <td>1326</td>\n",
       "      <td>2750</td>\n",
       "      <td>877.0</td>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>547</td>\n",
       "      <td>53.0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1037</td>\n",
       "      <td>462</td>\n",
       "      <td>3994</td>\n",
       "      <td>775.0</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "      <td>2757</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>2735</td>\n",
       "      <td>11946</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>1536</td>\n",
       "      <td>13</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>5801</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.090909</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Number words female  Total words  Number of words lead  \\\n",
       "0         0                 1512         6394                2251.0   \n",
       "1         1                 1524         8780                2020.0   \n",
       "2         2                  155         4176                 942.0   \n",
       "3         3                 1073         9855                3440.0   \n",
       "4         4                 1317         7688                3835.0   \n",
       "...     ...                  ...          ...                   ...   \n",
       "1034   1034                  303         2398                1334.0   \n",
       "1035   1035                  632         8404                1952.0   \n",
       "1036   1036                 1326         2750                 877.0   \n",
       "1037   1037                  462         3994                 775.0   \n",
       "1038   1038                 2735        11946                3410.0   \n",
       "\n",
       "      Difference in words lead and co-lead  Number of male actors  Year  \\\n",
       "0                                      343                      2  1995   \n",
       "1                                     1219                      9  2001   \n",
       "2                                      787                      7  1968   \n",
       "3                                     2623                     12  2002   \n",
       "4                                     3149                      8  1988   \n",
       "...                                    ...                    ...   ...   \n",
       "1034                                  1166                      5  1973   \n",
       "1035                                   187                      6  1992   \n",
       "1036                                   356                      2  2000   \n",
       "1037                                    52                      8  1996   \n",
       "1038                                  1536                     13  2007   \n",
       "\n",
       "      Number of female actors  Number words male  Gross  Mean Age Male  \\\n",
       "0                           5               2631  142.0      51.500000   \n",
       "1                           4               5236   37.0      39.125000   \n",
       "2                           1               3079  376.0      42.500000   \n",
       "3                           2               5342   19.0      35.222222   \n",
       "4                           4               2536   40.0      45.250000   \n",
       "...                       ...                ...    ...            ...   \n",
       "1034                        2                761  174.0      43.200000   \n",
       "1035                        2               5820  172.0      37.166667   \n",
       "1036                        3                547   53.0      27.500000   \n",
       "1037                        3               2757   32.0      42.857143   \n",
       "1038                        4               5801   32.0      44.090909   \n",
       "\n",
       "      Mean Age Female  Age Lead  Age Co-Lead    Lead  \n",
       "0           42.333333      46.0         65.0  Female  \n",
       "1           29.333333      58.0         34.0    Male  \n",
       "2           37.000000      46.0         37.0    Male  \n",
       "3           21.500000      33.0         23.0    Male  \n",
       "4           45.000000      36.0         39.0    Male  \n",
       "...               ...       ...          ...     ...  \n",
       "1034        31.000000      46.0         24.0    Male  \n",
       "1035        24.000000      21.0         34.0  Female  \n",
       "1036        27.666667      28.0         25.0    Male  \n",
       "1037        38.500000      29.0         32.0  Female  \n",
       "1038        50.000000      38.0         48.0    Male  \n",
       "\n",
       "[1039 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'train.csv'\n",
    "dataset = pd.read_csv(url, na_values='?', dtype={'ID': str}).dropna().reset_index()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "##\n",
    "\n",
    "def pre_process(raw_data, has_lead = True):\n",
    "    data = raw_data.copy()\n",
    "    \n",
    "    if has_lead:\n",
    "        data['Lead'] = pd.get_dummies(data['Lead'])\n",
    "\n",
    "    data['Number of words co-lead'] = data['Number of words lead'] - data['Difference in words lead and co-lead']\n",
    "    data['Proportion of words lead'] = data['Number of words lead']/data['Total words']\n",
    "    data['Proportion of words co-lead'] = data['Number of words co-lead']/data['Total words']\n",
    "    data['Ratio words co-lead lead'] = data['Number of words co-lead']/data['Number of words lead']\n",
    "    data['Proportion of words female'] = data['Number words female']/(data['Total words'] - data['Number of words lead'])\n",
    "    data['Proportion of female actors'] = data['Number of female actors']/(data['Number of male actors'] + data['Number of female actors'])\n",
    "    data['Older lead'] = data['Age Lead'] < data['Age Co-Lead']\n",
    "    data['Older lead'] = pd.get_dummies(data['Older lead'])\n",
    "    data['Number of actors'] = data['Number of male actors'] + data['Number of female actors']\n",
    "     \n",
    "    return data\n",
    "\n",
    "def fit_and_test(classifier, train, test, features, target, suppress_output = False):\n",
    "    classifier.fit(train[features], train[target])\n",
    "    if not suppress_output:\n",
    "        skl_met.plot_roc_curve(classifier, test[features], test[target])\n",
    "        print('accuracy: ' + str(classifier.score(test[features], test[target])))\n",
    "        print('     auc: ' + str(skl_met.roc_auc_score(test[target], classifier.predict_proba(test[features])[:,1])) + '\\n')\n",
    "        print(skl_met.classification_report(test[target], classifier.predict(test[features])))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy for model QuadraticDiscriminantAnalysis() is \n",
      "0.9441553544494721\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Accuracy estimation using cross validation to lower variance\n",
    "##\n",
    "\n",
    "#X = dataset[dataset.columns[1:14]]\n",
    "X = pre_process(dataset).drop(columns=['Lead'])\n",
    "X=X[{\n",
    "    'Year',\n",
    "    'Gross',\n",
    "    'Number of actors',\n",
    "    'Proportion of female actors',\n",
    "    'Mean Age Male',\n",
    "    'Mean Age Female',\n",
    "    'Age Lead',\n",
    "    'Age Co-Lead',\n",
    "    'Total words',\n",
    "    'Proportion of words lead',\n",
    "    'Proportion of words co-lead',\n",
    "    'Proportion of words female',\n",
    "    'Older lead'}]\n",
    "\n",
    "Y = dataset['Lead']\n",
    "# Split randomized data into training and validation (30% validation)\n",
    "X_train, X_val, Y_train, Y_val = skl_ms.train_test_split(X,Y, test_size=0.1)\n",
    "# List of models\n",
    "models = []\n",
    "#models.append(skl_lm.LogisticRegression(solver='liblinear'))\n",
    "#models.append(skl_da.LinearDiscriminantAnalysis())\n",
    "models.append(skl_da.QuadraticDiscriminantAnalysis())\n",
    "\n",
    "n_fold=20\n",
    "accuracy = np.zeros((n_fold, len(models)))\n",
    "model_accuracy = np.zeros(len(models))\n",
    "cv = skl_ms.KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(cv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    Y_train, Y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
    "    \n",
    "    for m in range(np.shape(models)[0]):\n",
    "        model = models[m]\n",
    "        model.fit(X_train, Y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "        accuracy[i,m] = np.mean(prediction == Y_val)\n",
    "        model_accuracy[m] += accuracy[i,m]\n",
    "for m in range(np.shape(models)[0]):\n",
    "    print('Model accuracy for model ' + str(models[m]) + ' is ')\n",
    "    print(model_accuracy[m]/n_fold)     \n",
    "\n",
    "plot = plt.figure(figsize=(20,5))\n",
    "ax = plot.add_subplot(111)\n",
    "bp = ax.boxplot(accuracy, vert=False)\n",
    "plot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy change after transformation QuadraticDiscriminantAnalysis() is \n",
      "0.006500000000000199\n"
     ]
    }
   ],
   "source": [
    "## Used to compare effects on accuracy of dropping inputs\n",
    "##\n",
    "\n",
    "#X = dataset.drop(columns=['Lead'])\n",
    "#X = pre_process(dataset).drop(columns=['Lead', 'index'])\n",
    "X = pre_process(dataset).drop(columns=['Lead', 'Difference in words lead and co-lead','Number of female actors','Number of male actors','Number of words co-lead','Number of words lead','Number words female','Number words male','index'])\n",
    "X2 = pre_process(dataset).drop(columns=['Lead', 'Difference in words lead and co-lead','Number of female actors','Number of male actors','Number of words co-lead','Number of words lead','Number words female','Number words male','index','Ratio words co-lead lead', 'Gross', 'Year'])\n",
    "Y = dataset['Lead']\n",
    "\n",
    "# List of models\n",
    "models = []\n",
    "#models.append(skl_lm.LogisticRegression(solver='liblinear'))\n",
    "#models.append(skl_da.LinearDiscriminantAnalysis())\n",
    "models.append(skl_da.QuadraticDiscriminantAnalysis())\n",
    "\n",
    "n_fold=200\n",
    "accuracy = np.zeros((n_fold, len(models)))\n",
    "accuracy2 = np.zeros((n_fold, len(models)))\n",
    "model_accuracy = np.zeros(len(models))\n",
    "model_accuracy2 = np.zeros(len(models))\n",
    "\n",
    "\n",
    "cv = skl_ms.KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(cv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    X2_train, X2_val = X2.iloc[train_index], X2.iloc[val_index]\n",
    "    Y_train, Y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
    "    \n",
    "    for m in range(np.shape(models)[0]):\n",
    "        model = models[m]\n",
    "        model.fit(X_train, Y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "        accuracy[i,m] = np.mean(prediction == Y_val)\n",
    "        model_accuracy[m] += accuracy[i,m]\n",
    "        \n",
    "        model.fit(X2_train, Y_train)\n",
    "        prediction = model.predict(X2_val)\n",
    "        accuracy[i,m] = np.mean(prediction == Y_val)\n",
    "        model_accuracy2[m] += accuracy[i,m]\n",
    "\n",
    "for m in range(np.shape(models)[0]):\n",
    "    print('Model accuracy change after transformation ' + str(models[m]) + ' is ')\n",
    "    print((model_accuracy2[m]-model_accuracy[m])/n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "\n",
      "Lead    Female  Male\n",
      "row_0               \n",
      "Female      72     6\n",
      "Male         9   225 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Confusion Matrix\n",
    "##\n",
    "\n",
    "#model = skl_da.LinearDiscriminantAnalysis()\n",
    "model = skl_da.QuadraticDiscriminantAnalysis()\n",
    "\n",
    "X = pre_process(dataset).drop(columns=['Lead'])\n",
    "X=X[{\n",
    "    'Number of actors',\n",
    "    'Proportion of female actors',\n",
    "    'Mean Age Male',\n",
    "    'Mean Age Female',\n",
    "    'Age Lead',\n",
    "    'Age Co-Lead',\n",
    "    'Total words',\n",
    "    'Proportion of words lead',\n",
    "    'Proportion of words co-lead',\n",
    "    'Proportion of words female',\n",
    "    'Older lead'}]\n",
    "\n",
    "Y = dataset['Lead']\n",
    "X_train, X_val, Y_train, Y_val = skl_ms.train_test_split(X,Y, test_size=0.3)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "predict_prob = model.predict_proba(X_val)\n",
    "prediction = np.empty(len(X_val), dtype=object)\n",
    "prediction = np.where(predict_prob[:,0]>1/2, 'Female', 'Male')\n",
    "\n",
    "print(\"Confusion matrix: \\n\")\n",
    "\n",
    "print(pd.crosstab(prediction, Y_val), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.8985817307692308\n",
      "     mean auc: 0.9166185737732687\n",
      "     std auc: 0.014562959052339772\n",
      "     std auc: 0.01908021704437334\n"
     ]
    }
   ],
   "source": [
    "## Bootstrapping\n",
    "##\n",
    "classifier = skl_da.LinearDiscriminantAnalysis()\n",
    "features = [\n",
    "    'Number of actors',\n",
    "    'Proportion of female actors',\n",
    "    'Mean Age Male',\n",
    "    'Mean Age Female',\n",
    "    'Age Lead',\n",
    "    'Age Co-Lead',\n",
    "    'Total words',\n",
    "    'Proportion of words lead',\n",
    "    'Proportion of words co-lead',\n",
    "    'Proportion of words female',\n",
    "    'Older lead',\n",
    "]\n",
    "target = 'Lead'\n",
    "X = pre_process(dataset)\n",
    "X=X[{\n",
    "    'Number of actors',\n",
    "    'Proportion of female actors',\n",
    "    'Mean Age Male',\n",
    "    'Mean Age Female',\n",
    "    'Age Lead',\n",
    "    'Age Co-Lead',\n",
    "    'Total words',\n",
    "    'Proportion of words lead',\n",
    "    'Proportion of words co-lead',\n",
    "    'Proportion of words female',\n",
    "    'Older lead', 'Lead'}]\n",
    "B = 400 # number of training sets to sample\n",
    "accuracies = []\n",
    "aucs = []\n",
    "for i in range(B):\n",
    "    train, test = skl_ms.train_test_split(X, test_size=0.3)\n",
    "    QDA = fit_and_test(classifier, train, test, features, target, suppress_output=True)\n",
    "    accuracies.append(QDA.score(test[features], test[target]))\n",
    "    aucs.append(skl_met.roc_auc_score(test[target], QDA.predict_proba(test[features])[:,1]))\n",
    "\n",
    "print('mean accuracy: ' + str(np.mean(accuracies)))\n",
    "print('     mean auc: ' + str(np.mean(aucs)))\n",
    "\n",
    "print('     std auc: ' + str(np.std(accuracies)))\n",
    "print('     std auc: ' + str(np.std(aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy: 0.9444\n",
      "Best accuracy features {'Total words', 'Proportion of words lead', 'Proportion of words female', 'Proportion of female actors', 'Number of actors', 'Age Co-Lead', 'Older lead', 'Mean Age Male', 'Ratio words co-lead lead', 'Proportion of words co-lead', 'Age Lead', 'Mean Age Female'}\n",
      "Maximum auc: 0.9846\n",
      "Best AUC features {'Total words', 'Proportion of words lead', 'Proportion of words female', 'Proportion of female actors', 'Number of actors', 'Age Co-Lead', 'Older lead', 'Mean Age Male', 'Ratio words co-lead lead', 'Proportion of words co-lead', 'Age Lead', 'Mean Age Female'}\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "## Used to find optimal combinations of inputs\n",
    "## \n",
    "\n",
    "classifier = skl_da.QuadraticDiscriminantAnalysis()\n",
    "factors = [\n",
    "    'Number of actors',\n",
    "    'Proportion of female actors',\n",
    "    'Mean Age Male',\n",
    "    'Mean Age Female',\n",
    "    'Age Lead',\n",
    "    'Age Co-Lead',\n",
    "    'Total words',\n",
    "    'Proportion of words lead',\n",
    "    'Proportion of words co-lead',\n",
    "    'Ratio words co-lead lead',\n",
    "    'Proportion of words female',\n",
    "    'Older lead',\n",
    "]\n",
    "target = 'Lead'\n",
    "X = pre_process(dataset).drop(columns=['Difference in words lead and co-lead','Number of female actors','Number of male actors','Number of words co-lead','Number of words lead','Number words female','Number words male','index'])\n",
    "#for feature in features:\n",
    "#    X[feature + '2'] = X[feature]**2\n",
    "#    X[feature + '3'] = X[feature]**3\n",
    "    \n",
    "#all_features = features + [feature + '2' for feature in features] + [feature + '3' for feature in features]\n",
    "max_accuracy = 0\n",
    "max_auc = 0\n",
    "best_features_accuracy = {}\n",
    "best_features_auc = {}\n",
    "B = 2 #number of bootstrapped training sets\n",
    "for features in itertools.combinations(factors, len(factors)):\n",
    "    accuracies = []\n",
    "    aucs = []\n",
    "    for i in range(B):\n",
    "        train, test = skl_ms.train_test_split(X, train_size=0.3)\n",
    "        QDA = fit_and_test(classifier, train, test, set(features), target, suppress_output=True)\n",
    "        accuracies.append(QDA.score(test[set(features)], test[target]))\n",
    "        aucs.append(skl_met.roc_auc_score(test[target], QDA.predict_proba(test[set(features)])[:,1]))\n",
    "        accuracy = np.mean(accuracies)\n",
    "        auc = np.mean(aucs)\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        best_features_accuracy = set(features)\n",
    "    if auc > max_auc:\n",
    "        max_auc = auc\n",
    "        best_features_auc = set(features)\n",
    "\n",
    "print(f'Maximum accuracy: {max_accuracy:.4f}')\n",
    "print('Best accuracy features', best_features_accuracy)\n",
    "print(f'Maximum auc: {max_auc:.4f}')\n",
    "print('Best AUC features', best_features_auc) \n",
    "print(set(factors)-set(best_features_accuracy))\n",
    "print(set(factors)-set(best_features_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Year     Gross\n",
      "index                                 0.139381 -0.089752\n",
      "Number words female                   0.010035 -0.115476\n",
      "Total words                          -0.001107 -0.060318\n",
      "Number of words lead                  0.011897 -0.116781\n",
      "Difference in words lead and co-lead  0.017550 -0.100437\n",
      "Number of male actors                -0.034118  0.114771\n",
      "Year                                  1.000000 -0.247108\n",
      "Number of female actors               0.086962 -0.118716\n",
      "Number words male                    -0.018908  0.052769\n",
      "Gross                                -0.247108  1.000000\n",
      "Mean Age Male                         0.054764  0.048568\n",
      "Mean Age Female                       0.157537 -0.075127\n",
      "Age Lead                              0.064871 -0.016425\n",
      "Age Co-Lead                           0.146755 -0.074578\n",
      "                                          Year     Gross\n",
      "index                                 0.158640 -0.097605\n",
      "Number words female                   0.105889 -0.084905\n",
      "Total words                           0.066809 -0.073323\n",
      "Number of words lead                  0.097921 -0.087531\n",
      "Difference in words lead and co-lead  0.117805 -0.106348\n",
      "Number of male actors                -0.060733  0.024021\n",
      "Year                                  1.000000 -0.408265\n",
      "Number of female actors               0.199836 -0.111241\n",
      "Number words male                    -0.024132 -0.011570\n",
      "Gross                                -0.408265  1.000000\n",
      "Mean Age Male                         0.042925  0.044128\n",
      "Mean Age Female                       0.197008  0.018413\n",
      "Age Lead                              0.165503 -0.047850\n",
      "Age Co-Lead                           0.110815 -0.039684\n"
     ]
    }
   ],
   "source": [
    "man = dataset[dataset['Lead']=='Male']\n",
    "kvinna = dataset[dataset['Lead']=='Female']\n",
    "print(man.corr()[['Year','Gross']])\n",
    "print(kvinna.corr()[['Year','Gross']])\n",
    "#dataset.corr()[[man['Year'], man['Gross']]\n",
    "#dataset.corr()[[kvinna['Year'], kvinna['Gross']]\n",
    "#dataset.corr()[['Year', 'Gross']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pre_process(dataset)\n",
    "X = processed[factors]\n",
    "\n",
    "Y = processed['Lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_raw = pd.read_csv('test.csv', na_values='?', dtype={'ID': str}).dropna().reset_index()\n",
    "test_set = pre_process(test_set_raw, False)[factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = skl_da.QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X,Y)\n",
    "\n",
    "preds = qda.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2248062015503876"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"predictions.csv\", \"w+\")\n",
    "try:\n",
    "    for pred in preds[:-1]:\n",
    "        f.write(f'{pred},')\n",
    "    f.write(f'{preds[-1]}')\n",
    "finally:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv('predictions.csv',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  377  378  379  380  \\\n",
       "0    0    0    0    0    0    0    1    0    0    0  ...    1    0    0    0   \n",
       "\n",
       "   381  382  383  384  385  386  \n",
       "0    1    0    0    1    0    0  \n",
       "\n",
       "[1 rows x 387 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('predictions.csv',header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
